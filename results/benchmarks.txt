Test write before runs
--------------------------------------------------
File Name: no_udf
Date: Sun Jun 30 01:14:02 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/30 13:11:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:========>                                                 (3 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20][Stage 1:======================================================>  (19 + 1) / 20]                                                                                [Stage 2:>                                                         (0 + 4) / 20][Stage 2:=====>                                                    (2 + 4) / 20][Stage 2:===========>                                              (4 + 4) / 20][Stage 2:=================>                                        (6 + 4) / 20][Stage 2:====================>                                     (7 + 4) / 20][Stage 2:=======================>                                  (8 + 4) / 20][Stage 2:============================>                            (10 + 4) / 20][Stage 2:==================================>                      (12 + 4) / 20][Stage 2:=====================================>                   (13 + 4) / 20][Stage 2:==========================================>              (15 + 4) / 20][Stage 2:=============================================>           (16 + 4) / 20][Stage 2:================================================>        (17 + 3) / 20][Stage 2:===================================================>     (18 + 2) / 20][Stage 4:>                                                          (0 + 4) / 4][Stage 4:==============>                                            (1 + 3) / 4][Stage 7:>                                                          (0 + 1) / 1]                                                                                {'read_time': 5.657984972000122, 'op_time': 0.04619860649108887, 'write_time': 82.45952010154724, 'avg_cpu_usage': 91.00666666666665, 'avg_memory_usage': 2.9947335137261284, 'peak_memory_usage': 3.3861312866210938}
--------------------------------------------------
--------------------------------------------------
File Name: scala_udf
Date: Sun Jun 30 01:15:28 PM CEST 2024
Results:
24/06/30 13:14:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:========>                                                 (3 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:==============>                                           (5 + 5) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20]                                                                                   read_time   op_time  ...  avg_memory_usage  peak_memory_usage
0   5.344337  0.135304  ...          2.936836           3.115112

[1 rows x 6 columns]
--------------------------------------------------
--------------------------------------------------
File Name: python_udf
Date: Sun Jun 30 01:18:25 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/30 13:15:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:============================>                            (10 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:==================================>                      (12 + 5) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20][Stage 1:======================================================>  (19 + 1) / 20]                                                                                {'read_time': 5.43295955657959, 'op_time': 0.06918811798095703, 'write_time': 164.11715579032898, 'avg_cpu_usage': 97.84117647058824, 'avg_memory_usage': 3.081081210865694, 'peak_memory_usage': 3.3353118896484375}
--------------------------------------------------
--------------------------------------------------
File Name: pandas_udf
Date: Sun Jun 30 01:20:23 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/30 13:18:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/home/nafra/.cache/pypoetry/virtualenvs/spark-handson-yJ0s0PsT-py3.10/lib/python3.10/site-packages/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.
  warnings.warn(
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:========>                                                 (3 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:============================>                            (10 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20][Stage 1:======================================================>  (19 + 1) / 20]                                                                                   read_time   op_time  ...  avg_memory_usage  peak_memory_usage
0    3.96636  0.090676  ...          3.293096           3.625404

[1 rows x 6 columns]
--------------------------------------------------
--------------------------------------------------
DBT Commands Output
Date: Sun Jun 30 01:20:23 PM CEST 2024
DBT Compile Results:
./run_benchmarks.sh: line 64: dbt: command not found
DBT Run Results:
./run_benchmarks.sh: line 67: dbt: command not found
--------------------------------------------------
Test write after runs
