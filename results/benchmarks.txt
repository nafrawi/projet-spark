Test write before runs
--------------------------------------------------
File Name: no_udf
Date: Sat Jun 29 05:54:20 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/29 17:52:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:========>                                                 (3 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:===================================================>     (18 + 2) / 20]                                                                                [Stage 2:>                                                         (0 + 4) / 20][Stage 2:==>                                                       (1 + 4) / 20][Stage 2:========>                                                 (3 + 4) / 20][Stage 2:===========>                                              (4 + 4) / 20][Stage 2:==============>                                           (5 + 4) / 20][Stage 2:=================>                                        (6 + 4) / 20][Stage 2:=======================>                                  (8 + 4) / 20][Stage 2:============================>                            (10 + 4) / 20][Stage 2:===============================>                         (11 + 4) / 20][Stage 2:==================================>                      (12 + 4) / 20][Stage 2:=====================================>                   (13 + 4) / 20][Stage 2:=============================================>           (16 + 4) / 20][Stage 2:================================================>        (17 + 3) / 20][Stage 2:===================================================>     (18 + 2) / 20][Stage 4:>                                                          (0 + 4) / 4][Stage 4:============================================>              (3 + 1) / 4][Stage 7:>                                                          (0 + 1) / 1]                                                                                {'read_time': 5.535021543502808, 'op_time': 0.046378135681152344, 'write_time': 68.06597828865051, 'avg_cpu_usage': 92.1243243243243, 'avg_memory_usage': 3.890983169143264, 'peak_memory_usage': 4.1132354736328125}
--------------------------------------------------
--------------------------------------------------
File Name: scala_udf
Date: Sat Jun 29 05:55:55 PM CEST 2024
Results:
24/06/29 17:54:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:============================>                            (10 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:===================================================>     (18 + 2) / 20][Stage 1:======================================================>  (19 + 1) / 20]                                                                                   read_time   op_time  ...  avg_memory_usage  peak_memory_usage
0   5.442635  0.138362  ...             3.936           4.274082

[1 rows x 6 columns]
--------------------------------------------------
--------------------------------------------------
File Name: python_udf
Date: Sat Jun 29 05:58:57 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/29 17:55:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20]                                                                                {'read_time': 5.463721990585327, 'op_time': 0.07138895988464355, 'write_time': 170.6975061893463, 'avg_cpu_usage': 97.86363636363636, 'avg_memory_usage': 4.219497507268732, 'peak_memory_usage': 4.553741455078125}
--------------------------------------------------
--------------------------------------------------
File Name: pandas_udf
Date: Sat Jun 29 06:00:55 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/29 17:59:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/home/nafra/.cache/pypoetry/virtualenvs/spark-handson-yJ0s0PsT-py3.10/lib/python3.10/site-packages/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.
  warnings.warn(
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:============================>                            (10 + 5) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 3) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20][Stage 1:======================================================>  (19 + 1) / 20]                                                                                   read_time   op_time  ...  avg_memory_usage  peak_memory_usage
0   3.966741  0.066895  ...           4.35766           4.690666

[1 rows x 6 columns]
--------------------------------------------------
Test write after runs
