Test write before runs
--------------------------------------------------
File Name: no_udf
Date: Sat Jun 29 07:02:57 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/29 19:00:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:>                                                         (0 + 6) / 20][Stage 1:========>                                                 (3 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:============================>                            (10 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:===================================================>     (18 + 2) / 20]                                                                                [Stage 2:>                                                         (0 + 4) / 20][Stage 2:========>                                                 (3 + 4) / 20][Stage 2:===========>                                              (4 + 4) / 20][Stage 2:==============>                                           (5 + 4) / 20][Stage 2:====================>                                     (7 + 4) / 20][Stage 2:=======================>                                  (8 + 4) / 20][Stage 2:==========================>                               (9 + 4) / 20][Stage 2:============================>                            (10 + 4) / 20][Stage 2:===============================>                         (11 + 4) / 20][Stage 2:==================================>                      (12 + 4) / 20][Stage 2:=====================================>                   (13 + 4) / 20][Stage 2:=======================================>                 (14 + 4) / 20][Stage 2:==========================================>              (15 + 4) / 20][Stage 2:=============================================>           (16 + 4) / 20][Stage 2:================================================>        (17 + 3) / 20][Stage 2:===================================================>     (18 + 2) / 20][Stage 2:======================================================>  (19 + 1) / 20][Stage 4:>                                                          (0 + 4) / 4][Stage 4:=============================>                             (2 + 2) / 4][Stage 7:>                                                          (0 + 1) / 1]                                                                                {'read_time': 5.8527185916900635, 'op_time': 0.05031704902648926, 'write_time': 72.47460007667542, 'avg_cpu_usage': 91.21500000000002, 'avg_memory_usage': 3.747870922088623, 'peak_memory_usage': 3.938182830810547}
--------------------------------------------------
--------------------------------------------------
File Name: scala_udf
Date: Sat Jun 29 07:04:34 PM CEST 2024
Results:
24/06/29 19:03:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:=====>                                                    (2 + 4) / 20][Stage 1:========>                                                 (3 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:============================>                            (10 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20][Stage 1:======================================================>  (19 + 1) / 20]                                                                                   read_time   op_time  ...  avg_memory_usage  peak_memory_usage
0    5.82692  0.153319  ...          3.726624           3.927654

[1 rows x 6 columns]
--------------------------------------------------
--------------------------------------------------
File Name: python_udf
Date: Sat Jun 29 07:08:32 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/29 19:04:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                         (0 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:============================>                            (10 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:=======================================>                 (14 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20][Stage 1:======================================================>  (19 + 1) / 20]                                                                                {'read_time': 8.08907699584961, 'op_time': 0.14465069770812988, 'write_time': 221.01751279830933, 'avg_cpu_usage': 98.62347826086958, 'avg_memory_usage': 4.184956558890964, 'peak_memory_usage': 4.650585174560547}
--------------------------------------------------
--------------------------------------------------
File Name: pandas_udf
Date: Sat Jun 29 07:10:47 PM CEST 2024
Results:
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/06/29 19:08:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/home/nafra/.cache/pypoetry/virtualenvs/spark-handson-yJ0s0PsT-py3.10/lib/python3.10/site-packages/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.
  warnings.warn(
[Stage 1:>                                                         (0 + 4) / 20][Stage 1:===========>                                              (4 + 4) / 20][Stage 1:==============>                                           (5 + 4) / 20][Stage 1:=================>                                        (6 + 4) / 20][Stage 1:====================>                                     (7 + 4) / 20][Stage 1:=======================>                                  (8 + 4) / 20][Stage 1:==========================>                               (9 + 4) / 20][Stage 1:============================>                            (10 + 4) / 20][Stage 1:===============================>                         (11 + 4) / 20][Stage 1:==================================>                      (12 + 4) / 20][Stage 1:=====================================>                   (13 + 4) / 20][Stage 1:==========================================>              (15 + 4) / 20][Stage 1:=============================================>           (16 + 4) / 20][Stage 1:================================================>        (17 + 3) / 20][Stage 1:===================================================>     (18 + 2) / 20][Stage 1:======================================================>  (19 + 1) / 20]                                                                                   read_time   op_time  ...  avg_memory_usage  peak_memory_usage
0   6.817306  0.083347  ...          4.464976           4.858521

[1 rows x 6 columns]
--------------------------------------------------
Test write after runs
